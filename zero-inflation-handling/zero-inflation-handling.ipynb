import os, json, numpy as np, pandas as pd

PROJECT = "/content/qsnn_methane_exec"   # same in every notebook
os.makedirs(PROJECT, exist_ok=True)

for folder in ["00_inputs", "01_outputs", "reports"]:
    os.makedirs(os.path.join(PROJECT, folder), exist_ok=True)

def save_json(path, obj):
    with open(path, "w") as f:
        json.dump(obj, f, indent=2)

def arr_report(name, X):
    X = np.asarray(X)
    finite = np.isfinite(X)
    out = {
        "name": name,
        "shape": list(X.shape),
        "dtype": str(X.dtype),
        "finite_frac": float(finite.mean()),
        "n_nan": int(np.isnan(X).sum()),
        "n_inf": int(np.isinf(X).sum()),
    }
    xf = X[finite]
    if xf.size:
        out.update({
            "min": float(xf.min()),
            "p1": float(np.percentile(xf, 1)),
            "p50": float(np.percentile(xf, 50)),
            "p99": float(np.percentile(xf, 99)),
            "max": float(xf.max()),
        })
    print(json.dumps(out, indent=2))
    return out
IN_PATH = os.path.join(PROJECT, "01_outputs", "01_fused_qaqc.parquet")
df = pd.read_parquet(IN_PATH)
print("Loaded:", IN_PATH, "| shape:", df.shape)

time_col = "Time" if "Time" in df.columns else "time"
TARGET_COL = "tracer_concentration"
n = len(df)
cut = int(0.80 * n)
train_df = df.iloc[:cut].copy()
test_df  = df.iloc[cut:].copy()
print("Train:", train_df.shape, "| Test:", test_df.shape)
ytr = train_df[TARGET_COL].astype(float).values
nonzero = ytr[ytr > 0]
eps = float(np.percentile(nonzero, 1)) if nonzero.size else 1e-12
eps = max(eps, 1e-12)
print("eps:", eps)

y_all = df[TARGET_COL].astype(float).values
zero_mask = (y_all <= eps).astype(np.int8)

# Simple confidence v1: penalize missingness per row
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
miss_row = df[numeric_cols].isna().mean(axis=1).values.astype(np.float32)

zero_conf = np.clip(1.0 - 0.8 * miss_row, 0.0, 1.0).astype(np.float32)

df["zero_mask"] = zero_mask
df["zero_confidence"] = zero_conf

report = {
    "eps": eps,
    "zero_mask_rate": float(zero_mask.mean()),
    "zero_conf_p10_p50_p90": [float(x) for x in np.percentile(zero_conf, [10,50,90])],
}
save_json(os.path.join(PROJECT, "reports", "02_zero_inflation_report.json"), report)
print(json.dumps(report, indent=2))

np.save(os.path.join(PROJECT, "01_outputs", "02_zero_mask.npy"), zero_mask)
np.save(os.path.join(PROJECT, "01_outputs", "02_zero_confidence.npy"), zero_conf)

OUT_PATH = os.path.join(PROJECT, "01_outputs", "02_zero_inflation_augmented.parquet")
df.to_parquet(OUT_PATH, index=False)
print("Wrote:", OUT_PATH)
y = df["tracer_concentration"].astype(float).values
eps = 1.01e-12
masked_nonzero = ((y > 0) & (y <= eps)).mean()
print("Fraction of nonzero values that got masked as zero:", masked_nonzero)
print("Count:", int(((y > 0) & (y <= eps)).sum()))


