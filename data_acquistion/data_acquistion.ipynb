import os, json, numpy as np, pandas as pd

PROJECT = "/content/qsnn_methane_exec"   # same in every notebook
os.makedirs(PROJECT, exist_ok=True)

for folder in ["00_inputs", "01_outputs", "reports"]:
    os.makedirs(os.path.join(PROJECT, folder), exist_ok=True)

def save_json(path, obj):
    with open(path, "w") as f:
        json.dump(obj, f, indent=2)

def arr_report(name, X):
    X = np.asarray(X)
    finite = np.isfinite(X)
    out = {
        "name": name,
        "shape": list(X.shape),
        "dtype": str(X.dtype),
        "finite_frac": float(finite.mean()),
        "n_nan": int(np.isnan(X).sum()),
        "n_inf": int(np.isinf(X).sum()),
    }
    xf = X[finite]
    if xf.size:
        out.update({
            "min": float(xf.min()),
            "p1": float(np.percentile(xf, 1)),
            "p50": float(np.percentile(xf, 50)),
            "p99": float(np.percentile(xf, 99)),
            "max": float(xf.max()),
        })
    print(json.dumps(out, indent=2))
    return out
from google.colab import files
import shutil

uploaded = files.upload()  # choose methane_data.csv (or your file)
csv_name = next(iter(uploaded.keys()))
src = f"/content/{csv_name}"
dst = os.path.join(PROJECT, "00_inputs", csv_name)
shutil.move(src, dst)
print("Saved input to:", dst)
CSV_PATH = os.path.join(PROJECT, "00_inputs", csv_name)  # uses uploaded name
df = pd.read_csv(CSV_PATH)

# Auto-detect time column (your dataset uses 'Time')
TIME_CANDIDATES = ["Time","time","timestamp","Timestamp","datetime","DateTime","date","Date"]
time_col = None
for c in TIME_CANDIDATES:
    if c in df.columns:
        parsed = pd.to_datetime(df[c], errors="coerce")
        if parsed.notna().mean() > 0.95:
            time_col = c
            df[c] = parsed
            break
if time_col is None:
    raise KeyError("No valid time column found.")

before = len(df)
df = df[df[time_col].notna()].copy()
df = df.sort_values(time_col).reset_index(drop=True)

report = {
    "csv_path": CSV_PATH,
    "shape": list(df.shape),
    "time_col": time_col,
    "dropped_invalid_time": int(before - len(df)),
    "time_monotonic": bool(df[time_col].is_monotonic_increasing),
    "columns": list(df.columns),
}
save_json(os.path.join(PROJECT, "reports", "00_acquisition_report.json"), report)
print(json.dumps(report, indent=2))

OUT_PATH = os.path.join(PROJECT, "01_outputs", "00_raw_parsed.parquet")
df.to_parquet(OUT_PATH, index=False)
print("Wrote:", OUT_PATH)
